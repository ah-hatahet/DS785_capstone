{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS785_capstone_code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-0gc9BPUoz7"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MNCv0zUoLa"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import jsonlines\n",
        "from transformers import pipeline\n",
        "from difflib import SequenceMatcher\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import networkx as nx\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
        "    Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoGwqlRTU5Tm"
      },
      "source": [
        "### Key functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83PPXUBgU9nU"
      },
      "source": [
        "# function to calculate similary between two sentences\n",
        "def similar(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZJwES28rA1s"
      },
      "source": [
        "# COSINE SIMILARITY MODEL FUNCTIONS\n",
        "\n",
        "# function to preprocess text by replacing puncuations with periods ('.') and splitting with spaces (' ') for easier text segmentation\n",
        "def preprocess_dialogue(dialogue):\n",
        "    dialogue = dialogue.replace('!','.').replace('?','.').split(\".#\")\n",
        "    sentences = []\n",
        "    for sentence in dialogue:\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    \n",
        "    return sentences\n",
        "\n",
        "# function to calculate similarity between two sentences\n",
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        " \n",
        "# function to create similarity matrix\n",
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    \n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: \n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "\n",
        "# cosine similarity summary generator\n",
        "def generate_summary(text):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Preprocess text\n",
        "    org_sentences =  preprocess_dialogue(text)\n",
        "    sentences = []\n",
        "    for sent in org_sentences:\n",
        "        if len(sent) > 1:\n",
        "            sentences.append(sent)\n",
        "\n",
        "    # Generate simialrity matrix\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Rank sentences\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Pick the most important sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    summarize_text = []\n",
        "    summary_size = round((40/(100)) * len(ranked_sentence))\n",
        "    for i in range(summary_size):\n",
        "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "    summary = \". \".join(summarize_text)\n",
        "    return summary"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lL72U_x0MN8"
      },
      "source": [
        "# 'Attention' layer architicture - Original source: https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjPbE7fHVK9_"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCgldWGZ02jU"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import jsonlines\n",
        "\n",
        "val_path = 'dialogsum.dev.jsonl'\n",
        "test_path = 'dialogsum.test.jsonl'\n",
        "train_path = 'dialogsum.train.jsonl'\n",
        "\n",
        "val = []\n",
        "with open(val_path, \"r+\", encoding=\"utf8\") as f:\n",
        "    for item in jsonlines.Reader(f):\n",
        "        val.append(item)\n",
        "    f.close()\n",
        "    \n",
        "test = []\n",
        "with open(test_path, \"r+\", encoding=\"utf8\") as f:\n",
        "    for item in jsonlines.Reader(f):\n",
        "        test.append(item)\n",
        "    f.close()\n",
        "      \n",
        "train = []\n",
        "with open(train_path, \"r+\", encoding=\"utf8\") as f:\n",
        "    for item in jsonlines.Reader(f):\n",
        "        train.append(item)\n",
        "    f.close()\n",
        "    \n",
        "    \n",
        "data = train+test+val\n",
        "assert len(data) == len(train) + len(test) + len(val)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df = df\n",
        "df['dialogue'] = df['dialogue'].str.replace('\\r', '')\n",
        "df['dialogue'] = df['dialogue'].str.replace('\\n', '')\n",
        "df['summary'] = df['summary'].str.replace('\\r', '')\n",
        "df['summary'] = df['summary'].str.replace('\\n', '')\n",
        "\n",
        "df = df[['dialogue','summary']]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62wzFXDoVvbX"
      },
      "source": [
        "## Remove empty rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmmQDaTFVxuO",
        "outputId": "cfd353f4-3a25-48b5-d9e3-a5acfff536e2"
      },
      "source": [
        "print(len(df))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c__ty2KuVz7k"
      },
      "source": [
        "df = df.dropna(axis=0, subset=['summary'])"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PtvrNmhV3jr",
        "outputId": "d837a61a-43e8-499a-bb36-43094ca0fd47"
      },
      "source": [
        "print(len(df))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hlbr7TjrWGYu",
        "outputId": "b0fdbb4c-45a4-46d2-a820-b60237b5d897"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dialogue</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...</td>\n",
              "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Person1#: Hello Mrs. Parker, how have you bee...</td>\n",
              "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#Person1#: Excuse me, did you see a set of key...</td>\n",
              "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Person1#: Why didn't you tell me you had a gi...</td>\n",
              "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Person1#: Watsup, ladies! Y'll looking'fine t...</td>\n",
              "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            dialogue                                            summary\n",
              "0  #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...  Mr. Smith's getting a check-up, and Doctor Haw...\n",
              "1  #Person1#: Hello Mrs. Parker, how have you bee...  Mrs Parker takes Ricky for his vaccines. Dr. P...\n",
              "2  #Person1#: Excuse me, did you see a set of key...  #Person1#'s looking for a set of keys and asks...\n",
              "3  #Person1#: Why didn't you tell me you had a gi...  #Person1#'s angry because #Person2# didn't tel...\n",
              "4  #Person1#: Watsup, ladies! Y'll looking'fine t...  Malik invites Nikki to dance. Nikki agrees if ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-L_a_9HWLww"
      },
      "source": [
        "## Plot the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "8S6pgAktWKP3",
        "outputId": "6ae6e4ec-261d-43f9-9715-684085db1779"
      },
      "source": [
        "dialogues_word_count = []\n",
        "summaries_word_count = []\n",
        "\n",
        "for i in df['dialogue']:\n",
        "    dialogues_word_count.append(len(i.split()))\n",
        "for i in df['summary']:\n",
        "    summaries_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'dialogues': dialogues_word_count, 'summaries': summaries_word_count})\n",
        "length_df.hist(bins=15)\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czNUcRExWQG4",
        "outputId": "9021bfab-f2d7-49ef-84d8-ba96e9eb293b"
      },
      "source": [
        "count = 0\n",
        "for i in df['dialogue']:\n",
        "    if(len(i.split())<=500):\n",
        "        count += 1\n",
        "print(count/len(df['dialogue']))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9977623456790123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2G_P94MWSIQ",
        "outputId": "e3ada01e-8706-484a-ba9f-8a541f5eb396"
      },
      "source": [
        "count = 0\n",
        "for i in df['summary']:\n",
        "    if(len(i.split())<=100):\n",
        "        count += 1\n",
        "print(count/len(df['dialogue']))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9993055555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJUeHhmHWT1h"
      },
      "source": [
        "Most dialogues (99.8%) have lengths of 500 maximum while most summaries (99.9%) have lengths of 100 maximum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWbSYZZ5WWk6"
      },
      "source": [
        "## Split the data into train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiDszKAMWad8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(np.array(df['dialogue']),np.array(df['summary']),test_size=0.1,random_state=10,shuffle=True)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE1evfiHWr9V"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-I1TJNSWud1"
      },
      "source": [
        "HuggingFace Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9kOpUaGWhOm",
        "outputId": "add2be60-90d1-4919-880f-fb107e3442dd"
      },
      "source": [
        "i = 5\n",
        "to_tokenize = df.iloc[i,0]\n",
        "label = df.iloc[i,1]\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarized = summarizer(to_tokenize, min_length=5, max_length=len(to_tokenize)//4)\n",
        "\n",
        "summary = summarized[0]['summary_text']\n",
        "\n",
        "# Print summarized text\n",
        "print('original text:', to_tokenize)\n",
        "print()\n",
        "print('original summary:',label)\n",
        "print()\n",
        "print('new summary:',summary)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original text: #Person1#: Happy birthday, Aims!#Person2#: Thank you, Lisa.#Person1#: Here is a present for you. I hope you like it.#Person2#: Oh, great! I love it! You know I've been expecting this for a long time.#Person1#: I'm very glad to hear that.#Person2#: Come here ; let me introduce some friends to you.\n",
            "\n",
            "original summary: Lisa gives Aims a birthday present and Aims loves it.\n",
            "\n",
            "new summary:  #Person1#: Happy birthday, Aims!#Person2#: Thank you, Lisa. I hope you like it. I've been expecting this for a long time. I love it! You know I'm very glad to hear that. Come here ; let me introduce some friends to you .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLbqSb5cWyh-",
        "outputId": "478fc913-1657-4307-97a1-265c8a1a8c1a"
      },
      "source": [
        "similar(summary, label)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20437956204379562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcJujptTj7Hr"
      },
      "source": [
        "Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOsBQO1Zj6iq"
      },
      "source": [
        "summary = generate_summary( df.iloc[i,0])\n",
        "\n",
        "# Print summarized text\n",
        "print('original text:', to_tokenize)\n",
        "print()\n",
        "print('original summary:',label)\n",
        "print()\n",
        "print('new summary:',summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5jsf6KlW6TK"
      },
      "source": [
        "Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzoa0_1okFHI"
      },
      "source": [
        "similar(summary, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTst7BM3W9TW"
      },
      "source": [
        "# TOKENIZATION\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_summary_len=100\n",
        "max_dialogue_len=600\n",
        "\n",
        "# Tokenize X_train\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "thresh=4\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "x_tr_seq = x_tokenizer.texts_to_sequences(x_train) \n",
        "x_val_seq = x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "#padding zero upto max_len\n",
        "x_train = pad_sequences(x_tr_seq,  maxlen=max_dialogue_len, padding='post')\n",
        "x_test = pad_sequences(x_val_seq, maxlen=max_dialogue_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKCLWjqAm1oW"
      },
      "source": [
        "# Tokenize y_train\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "thresh=6\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "y_train_seq    =   y_tokenizer.texts_to_sequences(y_train) \n",
        "y_test_seq   =   y_tokenizer.texts_to_sequences(y_test) \n",
        "\n",
        "#padding zero upto max_len\n",
        "y_train    =   pad_sequences(y_train_seq, maxlen=max_summary_len, padding='post')\n",
        "y_test   =   pad_sequences(y_test_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lY21M0f17xE",
        "outputId": "d0bb9f81-8e9c-4367-f0d9-7fb84a47362b"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 100\n",
        "embedding_dim = 110\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_dialogue_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 600)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 600, 110)     1031360     input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 600, 100), ( 84400       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 600, 100), ( 80400       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 110)    378400      input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 600, 100), ( 80400       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 100),  84400       embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 100),  20100       lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 200)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 3440)   691440      concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 2,450,900\n",
            "Trainable params: 2,450,900\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9I1X8pX1-Aa",
        "outputId": "5ef60df8-c7ae-4082-b688-1dc527c86bea"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=5,callbacks=[es],batch_size=128, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 687s 7s/step - loss: 1.3546 - val_loss: 1.2698\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 672s 7s/step - loss: 1.2628 - val_loss: 1.2095\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 668s 7s/step - loss: 1.1916 - val_loss: 1.1373\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 668s 7s/step - loss: 1.1333 - val_loss: 1.1017\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 667s 7s/step - loss: 1.0978 - val_loss: 1.0695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QbGx8Sx2Gj5"
      },
      "source": [
        "max_summary_len=100\n",
        "max_dialogue_len=600\n",
        "\n",
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_dialogue_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "          newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-KRAKLJhTYA"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vr63b3PhJ6X",
        "outputId": "39f8ff71-c50e-47cf-fffa-371da32488d2"
      },
      "source": [
        "# calculate the mean score for each model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train1,x_test1,y_train1,y_test1=train_test_split(np.array(df['dialogue']),np.array(df['summary']),test_size=0.1,random_state=10,shuffle=True)\n",
        "\n",
        "\n",
        "transformers_scores = []\n",
        "seq2seq_scores = []\n",
        "cosine_sim_scores = []\n",
        "for i in range(30):\n",
        "  print(i)\n",
        "\n",
        "  # labels for Seq2Seq (tokenized)\n",
        "  dialogue = x_test[i]\n",
        "  label = y_test[i]\n",
        "  # labels for Transformers and Cosine Sim (untokenized)\n",
        "  dialogue1 = x_test1[i]\n",
        "  label1 = y_test1[i]\n",
        "\n",
        "  # Transformers\n",
        "  summary = summarizer(dialogue1, min_length=5, max_length=len(dialogue)//4)[0]['summary_text']\n",
        "\n",
        "  transformers_scores.append(similar(summary, label))\n",
        "\n",
        "  # Seq2Seq\n",
        "  #summary = decode_sequence(dialogue.reshape(1,max_dialogue_len))\n",
        "  #seq2seq_scores.append(similar(summary, label1)) \n",
        "\n",
        "  # cosine similarity\n",
        "  summary = generate_summary( df.iloc[i,0])\n",
        "  cosine_sim_scores.append(similar(summary, label)) \n",
        "\n",
        "\n",
        "print('transformers mean score:', sum(transformers_scores)/len(transformers_scores))\n",
        "#print('seq2seq mean score:', sum(seq2seq_scores)/len(seq2seq_scores)) ## final score 0.11\n",
        "print('cosine similarity score:', sum(cosine_sim_scores)/len(cosine_sim_scores))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 83. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 75. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 86. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 149. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 90. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 79. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 86. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 134. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "11\n",
            "12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 130. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but you input_length is only 55. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29\n",
            "transformers mean score: 0.0\n",
            "cosine similarity score: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4rMETevs024"
      },
      "source": [
        "Note on Seq2Seq Evaluation: Because of some advanced preprocessing techniques used, code to generate summaries and (scores) from the seq2seq model got lost accidentaly making it difficult to figure it out again within the time limit. The score of 11% is based on the previous conclutions before the code broke. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMW0LfL3wimB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "163af354-5e65-4a29-ccbe-68bfd23c1b5f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(transformers_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([5., 1., 1., 1., 3., 3., 4., 6., 2., 4.]),\n",
              " array([0.01941748, 0.06885694, 0.11829641, 0.16773588, 0.21717535,\n",
              "        0.26661482, 0.31605428, 0.36549375, 0.41493322, 0.46437269,\n",
              "        0.51381215]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "21vtpmP5yDzP",
        "outputId": "18128bc8-adcd-44b6-b775-e5d14facac32"
      },
      "source": [
        "plt.hist(cosine_sim_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([6., 3., 2., 2., 2., 2., 4., 4., 2., 3.]),\n",
              " array([0.        , 0.04610592, 0.09221184, 0.13831776, 0.18442368,\n",
              "        0.2305296 , 0.27663551, 0.32274143, 0.36884735, 0.41495327,\n",
              "        0.46105919]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}